server:
  port: 8080
  shutdown: graceful

spring:
  application:
    name: MoheBatch
  main:
    allow-bean-definition-overriding: true
  
  datasource:
    url: ${DATABASE_URL:jdbc:postgresql://localhost:5432/mohe_db}
    username: ${DATABASE_USERNAME:mohe_user}
    password: ${DATABASE_PASSWORD:mohe_password}
    driver-class-name: org.postgresql.Driver
    hikari:
      connection-timeout: ${DB_CONNECTION_TIMEOUT:20000}
      maximum-pool-size: ${DB_MAX_POOL_SIZE:20}
      minimum-idle: ${DB_MIN_IDLE:5}
      idle-timeout: ${DB_IDLE_TIMEOUT:300000}
      max-lifetime: ${DB_MAX_LIFETIME:1200000}
      leak-detection-threshold: ${DB_LEAK_DETECTION_THRESHOLD:60000}
      auto-commit: false

  jpa:
    hibernate:
      ddl-auto: none  # Don't validate or create schema - using existing MoheSpring schema
    show-sql: ${JPA_SHOW_SQL:false}
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        jdbc:
          batch_size: 20
          order_inserts: true
          order_updates: true
        connection:
          provider_disables_autocommit: true
          isolation: 2  # READ_COMMITTED
        temp:
          use_jdbc_metadata_defaults: false

  flyway:
    enabled: false  # Disable Flyway - using existing MoheSpring database schema
    baseline-on-migrate: true
    validate-on-migrate: false

  batch:
    job:
      enabled: ${BATCH_AUTO_START:false}  # Can be enabled via environment variable
    initialize-schema: always  # Auto-create Spring Batch schema
    
  # Enable scheduling for batch jobs
  scheduling:
    enabled: true

# LLM Configuration - Strict separation as per requirements
# OpenAI: Description generation, keyword extraction, image prompts
# Ollama: Vector embeddings ONLY
openai:
  api-key: ${OPENAI_API_KEY:}
  model: ${OPENAI_MODEL:gpt-3.5-turbo}

ollama:
  host: ${OLLAMA_HOST:http://localhost:11434}
  embedding-model: ${OLLAMA_EMBEDDING_MODEL:mxbai-embed-large}

# Application-specific configuration
app:
  external:
    api:
      base-url: ${EXTERNAL_API_BASE_URL:https://openapi.naver.com}
      timeout: ${EXTERNAL_API_TIMEOUT:30}
    naver:
      base-url: https://openapi.naver.com/v1/search/local.json
      client-id: ${NAVER_CLIENT_ID:}
      client-secret: ${NAVER_CLIENT_SECRET:}
      page-size: ${NAVER_PAGE_SIZE:100}
      max-pages: ${NAVER_MAX_PAGES:20}
      timeout: ${NAVER_TIMEOUT:10}
      queries:
        - "카페"
        - "레스토랑"
        - "음식점"
        - "베이커리"
        - "디저트"
        - "공원"
        - "박물관"
        - "미술관"
        - "서점"
        - "영화관"
        - "헬스장"
        - "요가"
        - "필라테스"
        - "갤러리"
        - "문화센터"
        # 필터링 대상 제거: 클럽, 마트, 편의점, 스파 등
      seoul-coords:
        - { lat: 37.5665, lng: 126.9780, radius: 5000 }  # 중구 (명동, 종로)
        - { lat: 37.5172, lng: 127.0473, radius: 5000 }  # 강남구
        - { lat: 37.5440, lng: 127.0557, radius: 5000 }  # 성동구 (성수동)
        - { lat: 37.5219, lng: 126.9895, radius: 5000 }  # 용산구 (이태원)
        - { lat: 37.5636, lng: 126.9748, radius: 5000 }  # 중구 (명동)
        - { lat: 37.5502, lng: 126.9224, radius: 5000 }  # 마포구 (홍대)
        - { lat: 37.5465, lng: 127.0949, radius: 5000 }  # 광진구 (건대)
        - { lat: 37.5814, lng: 127.0097, radius: 5000 }  # 종로구 (인사동)
        - { lat: 37.5267, lng: 126.8956, radius: 5000 }  # 영등포구
        - { lat: 37.5326, lng: 126.9026, radius: 5000 }  # 마포구 (여의도)
        - { lat: 37.5797, lng: 126.9425, radius: 5000 }  # 서대문구
        - { lat: 37.6015, lng: 126.9298, radius: 5000 }  # 은평구
        - { lat: 37.5423, lng: 127.1000, radius: 5000 }  # 송파구
        - { lat: 37.5146, lng: 127.1060, radius: 5000 }  # 강동구
        - { lat: 37.4783, lng: 126.9516, radius: 5000 }  # 관악구
        
    google:
      base-url: https://maps.googleapis.com/maps/api/place
      api-key: ${GOOGLE_PLACES_API_KEY:}
      timeout: ${GOOGLE_TIMEOUT:15}
      search-radius: 100  # meters for nearby search
      photo-max-width: 400
  
  mohe-spring:
    base-url: ${MOHE_SPRING_BASE_URL:http://mohe-backend:8080}

  batch:
    job-name: ${BATCH_JOB_NAME:optimized-place-ingestion-job}
    chunk-size: ${BATCH_CHUNK_SIZE:10}  # Smaller chunks for faster processing
    skip-limit: ${BATCH_SKIP_LIMIT:50}  # Increase skip limit to avoid failures
    max-retries: ${BATCH_MAX_RETRIES:1}  # Reduce retries for speed
    api-timeout: ${BATCH_API_TIMEOUT:15s}  # Faster timeout
    strict-filtering: ${BATCH_STRICT_FILTERING:false}  # Skip filtering for speed
    auto-initialization: ${BATCH_AUTO_INITIALIZATION:false}
    continuous:
      enabled: ${APP_BATCH_CONTINUOUS_ENABLED:true}  # Enable continuous batch processing

  checkpoint:
    enabled: ${CHECKPOINT_ENABLED:true}  # Enable checkpoint system
    batch-name: ${CHECKPOINT_BATCH_NAME:place-ingestion-batch}
    region-type: ${CHECKPOINT_REGION_TYPE:sigungu}  # Process at 시/군/구 level
    auto-resume: ${CHECKPOINT_AUTO_RESUME:true}  # Resume from last checkpoint on restart

# Actuator configuration for monitoring
management:
  server:
    port: 8081
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,flyway
      base-path: /actuator
  endpoint:
    health:
      show-details: always
      show-components: always
    metrics:
      enabled: true
    prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:local}

# Logging configuration
logging:
  level:
    com.example.ingestion: ${LOG_LEVEL:INFO}
    org.springframework.batch: INFO
    org.springframework.web: INFO
    org.flywaydb: INFO
    org.hibernate.SQL: WARN
    org.hibernate.type.descriptor.sql.BasicBinder: WARN
  pattern:
    console: "%d{HH:mm:ss.SSS} [%thread] %-5level [%X{correlationId:-}] %logger{36} - %msg%n"
    file: "%d{ISO8601} [%thread] %-5level [%X{correlationId:-}] %logger{36} - %msg%n"

# OpenAPI/Swagger configuration
springdoc:
  api-docs:
    path: /v3/api-docs
  swagger-ui:
    path: /swagger-ui.html
    operationsSorter: alpha
    tagsSorter: alpha

---
# Local development profile
spring:
  config:
    activate:
      on-profile: local
  
  datasource:
    url: jdbc:postgresql://localhost:5432/ingestion_db
    
logging:
  level:
    com.example.ingestion: DEBUG
    org.springframework.batch: DEBUG

app:
  external:
    api:
      base-url: http://localhost:3000

---
# Development profile
spring:
  config:
    activate:
      on-profile: dev

logging:
  level:
    com.example.ingestion: DEBUG

app:
  external:
    api:
      base-url: ${EXTERNAL_API_BASE_URL:https://api-dev.example.com}

---
# Production profile
spring:
  config:
    activate:
      on-profile: prod

logging:
  level:
    com.example.ingestion: INFO
    org.springframework.batch: WARN

app:
  external:
    api:
      base-url: ${EXTERNAL_API_BASE_URL:https://api.example.com}

---
# Batch processing profile (for dedicated batch containers)
spring:
  config:
    activate:
      on-profile: batch
  
  batch:
    job:
      enabled: ${BATCH_AUTO_START:false}

# Enable batch scheduling
app:
  batch:
    scheduling:
      enabled: ${APP_BATCH_SCHEDULING_ENABLED:true}
      cron: ${APP_BATCH_SCHEDULING_CRON:0 */1 * * * ?}
    continuous:
      enabled: ${APP_BATCH_CONTINUOUS_ENABLED:false}
    image-generation:
      cli:
        command: ${GEMINI_CLI_CMD:gemini}
        args-template: ${GEMINI_CLI_ARGS_TPL:image:generate -p "{PROMPT}" -o "{OUTPUT}"}
        image-size: ${GEMINI_IMAGE_SIZE:1024x1024}
      publish:
        root-dir: ${PUBLISH_ROOT_DIR:/tmp/static}
        base-path: ${PUBLISH_BASE_PATH:/images/places}
      retry:
        max-attempts: 5
        initial-backoff-ms: ${BACKOFF_INITIAL_MS:30000}
        max-backoff-ms: ${BACKOFF_MAX_MS:600000}
      concurrency: ${MAX_CONCURRENCY:4}

logging:
  level:
    com.example.ingestion.batch: DEBUG
    com.example.ingestion.config: INFO