package com.mohe.batch.job;

import com.mohe.batch.entity.Place;
import com.mohe.batch.repository.PlaceRepository;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.batch.item.ItemReader;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Sort;

import java.util.Iterator;

/**
 * ì—…ë°ì´íŠ¸ìš© ItemReader
 * - crawler_found=falseì¸ ì¥ì†Œ ì½ê¸° (í¬ë¡¤ë§ ëŒ€ìƒê³¼ ë™ì¼)
 * - Worker IDë¡œ ë¶„ì‚° ì²˜ë¦¬
 * - OpenAI ì—†ì´ ë©”ë‰´/ì´ë¯¸ì§€/ë¦¬ë·°ë§Œ ì—…ë°ì´íŠ¸
 */
public class UpdateReader implements ItemReader<Place> {

    private static final Logger log = LoggerFactory.getLogger(UpdateReader.class);

    private final PlaceRepository placeRepository;
    private final int workerId;
    private final int totalWorkers;
    private final int pageSize;

    private int currentPage = 0;
    private Iterator<Place> currentBatch;
    private boolean hasMoreData = true;

    public UpdateReader(PlaceRepository placeRepository, int workerId, int totalWorkers, int pageSize) {
        this.placeRepository = placeRepository;
        this.workerId = workerId;
        this.totalWorkers = totalWorkers;
        this.pageSize = pageSize;

        log.info("ğŸ”„ UpdateReader ì´ˆê¸°í™”: workerId={}, totalWorkers={}, pageSize={}, ì¡°ê±´=crawler_found=false",
                workerId, totalWorkers, pageSize);
    }

    @Override
    public synchronized Place read() {
        // í˜„ì¬ ë°°ì¹˜ì—ì„œ ì½ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜í™˜
        if (currentBatch != null && currentBatch.hasNext()) {
            return currentBatch.next();
        }

        // ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ null ë°˜í™˜
        if (!hasMoreData) {
            return null;
        }

        // ë‹¤ìŒ í˜ì´ì§€ ë¡œë“œ
        loadNextBatch();

        // ë¡œë“œ í›„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜í™˜
        if (currentBatch != null && currentBatch.hasNext()) {
            return currentBatch.next();
        }

        return null;
    }

    private void loadNextBatch() {
        try {
            PageRequest pageRequest = PageRequest.of(currentPage, pageSize, Sort.by("id").ascending());

            // crawl_status=PENDINGì¸ ì¥ì†Œ ì¡°íšŒ (í¬ë¡¤ë§ ëŒ€ìƒ)
            Page<Place> page = placeRepository.findByCrawlStatusPendingAndIdModEquals(
                    workerId, totalWorkers, pageRequest
            );

            if (page.hasContent()) {
                currentBatch = page.getContent().iterator();
                log.info("ğŸ”„ [Worker {}] ì—…ë°ì´íŠ¸ ëŒ€ìƒ ë¡œë“œ: í˜ì´ì§€ {}, {}ê°œ ì¥ì†Œ (crawl_status=PENDING)",
                        workerId, currentPage, page.getNumberOfElements());
                currentPage++;
            } else {
                hasMoreData = false;
                log.info("ğŸ”„ [Worker {}] ëª¨ë“  ì—…ë°ì´íŠ¸ ëŒ€ìƒ ì²˜ë¦¬ ì™„ë£Œ", workerId);
            }

            if (!page.hasNext()) {
                hasMoreData = false;
            }

        } catch (Exception e) {
            log.error("ğŸ”„ [Worker {}] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {}", workerId, e.getMessage());
            hasMoreData = false;
        }
    }
}
